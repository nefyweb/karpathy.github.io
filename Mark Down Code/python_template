http://mybinder.org:/repo/snowde/templates

This is an interesting where command, that says if equal, then x else y.

mom1 = np.where(mom1 > 0, 1, 0)

Interesting: You can create the below method to create a dataframe out of a group by object:

grouped = blue.groupby(["fyearq", "fqtr"],as_index=False).count()

This approach is much better in creating a dataframe ou tof a group by object:

grouped = blue.groupby(["fyearq", "fqtr"])

for key, item in grouped:
    print grouped.get_group(key), "\n\n"
    
Another method:

df.groupby('A').apply(lambda x: x)

NB the last value in brackets is inportant because you have to identify which values you want ot keep in the dataframe

grouped = blue.groupby(["fyearq", "fqtr"])[["mom"]]

bloom = train_new.reset_index()
bloom.reindex(train_new["id"])
train_new = train_new.fillna(a_mean)
id_df = train_new[col].groupby('id').agg([np.mean, np.std, len]).reset_index()

grouped = merged.groupby(["fyearq", "fqtr", "ticker"]).agg([np.mean, np.sum, np.std, len]).reset_index()


for o in range(len(train_new)):
id_df = bloom[col].groupby('id')
a_mean = id_df.mean().reset_index()
train_new = train_new.fillna(a_mean)
sum(train_new.isnull().sum(axis=1))

train["std"] = train.groupby('id').y.std()
corr = train.corr().ix["y", "std"]

merged = pd.merge(price, fiscal, on="date", how="outer")


# NB ix is the pandas slicer. 
fire1 = fire.ix[[:0]]
fire2 = fire.ix[[2:]]
newfire = pd.concat([fire1, fire2], axis=1)

# NB this drops the second row heade
fire.columns = fire.columns.droplevel(1)

-> This is interesting, reminds you that you have to 
pd.merge(left, right, left_on='key1', right_on='key2')

# Interesting, merge and joing essentially means the same thing,
# slightly differnt way of writing it out. 

And then concatante the one that just copies and paste. 


Here I am first creating a separate datafrane, 

d = pd.DataFrame()
dates = pd.date_range('20040101', '20170101')
s = pd.Series(dates)
d["fdate"] = s

This is how you can create awesome files from /// to yyyymmdd
TEXT(A1,"yyyymmdd")  and then drag it down. 

There is a way to play around with excel in pandas.

import openpyxl

d = pd.DataFrame()
dates = pd.date_range('2004/01/01', '2017/01/01')

mask in dataframe is like where. (IF THEN statement)

The statement I am looking for is ht emap function, which maps for each x value.

prices["cusip"]= prices["cusip"].map(lambda x: x[:5] + '10')

MAP FOR SERIES, APPLY FRO FRAME

apply is on id arrays

Wow this is an awesom .isin list code:

prices = prices[~prices["tic"].isin(tickel)]

Wow there actually is a way to get numpy into dataframe:

df = pd.DataFrame({'mom1':mom1.tolist()})

df = pd.DataFrame(numpyobject)

Here is an intresting location function, this helps to achieve good things:

d["close"] = new_group["close"].loc[new_group["year"]>"2004"]

When you get this issue::: 

only integers, slices (`:`), ellipsis (`…`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices

Then you can fix it by first specifying a dataframe beforeyou do anything else:

mom2 = pd.DataFrame()
mom2['price_above'] = np.where(values > 0, 1, 0)

Melt is one of the most beautiful function that I have ever seen, it stacks columns.

keys = [c for c in mom_vol_n if c.startswith('mom_vol_')]
new = pd.melt(mom_vol_n, value_vars=keys, value_name='mom_v')


NB when you are running loops over a dictionary in python 2 then use
for i, v in varlist.iteritems():

in python 3 you only have to use:

for i, v in varlist.items():

But, you have to inlcue items. 


You can find dtyoe of column doing the following:

pandas["column"].dtype
no ()


Awesome this code is good for appen in for :

   framed = np.append(framed, [train_predictions], axis=0)


To force division to be float

from __future__ import division

To pass on certain type of warnings:

def warn(*args, **kwargs): pass


For max values
numpy.set_printoptions(threshold='nan')


load ./zero_cleaner.py
This is an interesting line of code, it actually helps you to visualy load any .py into your document.

There is even a way to pass variables between netbooks, see this link:

https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/

Awesome you can us the follwoing magic command to write a cell to a python 
document: 

%%writefile pythoncode.py


This is a way to load in your py code without visually showing the code:

%run zero_cleaner.py

Also if you compilef the class file in the same python version you can use it as a class by chanign it to .pyc and just imorting it with just using the name
zero_cleaner

normalized_df=(coy-coy.min())/(coy.max()-coy.min())

The below is a long approach that simply does what is done above:

scaler = preprocessing.MinMaxScaler()
scaled = scaler.fit_transform(values)
coy = pd.DataFrame(scaled)

Interesting, you can .value an entire dataframe:

values = coy.values

NB when merging items, makes sure that you are mergin items of the same type.

You normally import in string, meaning that your next iports should also be in string. You can import one file in string and the other one in auto format i.e. leave to default, and then group the frame together later on.

This is how to import string 

fiscal = pd.read_csv("fiscal_bo.csv", dtype=str)

how : {‘any’, ‘all’}
any : if any NA values are present, drop that label
all : if all values are NA, drop that label

How to install talib package: 
ta-lib: 0.4.9-np19py27_0 quantopian

conda install -c quantopian ta-lib=0.4.9

How to insert at a specific locatoin:

coy_df.insert(0,"rdq",rdq)

Range is still the best approach to make a long list over a certain number 
range(X.shape[1])

This is probably a better way to write the merged file or any big file, just cut it off :

data = pd.merge(data, nRuta_SAK, 
                            how='left',
                            left_on=['Ruta_SAK'], 
                            right_on=['Ruta_SAK'],
                            left_index=False, right_index=False, sort=True,
                            suffixes=('_x', '_y'), copy=False) 

This is what I have: 

py27 -> py27na (This is the one without talib possibly?) 

ta-lib: 0.4.9-np19py27_0 quantopian
I found a way to clone an environement: this means that you can have similar running packages:

dereksnow$ conda create -n py27na --clone py27

How to insert at a specific locatoin:

coy_df.insert(0,"rdq",rdq)

Range is still the best approach to make a long list over a certain number 
range(X.shape[1])

In terms of website: 

Nameserver changes are heavier, dns is less heavy.

Nameserver means that the full domain sits with someone else.

Nameserver changes host.

DNS only gives another the right to render I believe.

I actually want to read up on some of these stuff, and find out how much they are different. 

The following is some interesting Conda Code:

conda search python

conda install python=xxx.xxx

python --version

conda create -n py35 python=3.5 anaconda

conda update python

source activate py36

source deactivate py36

conda create -n py27 python=2.7 anaconda
conda create -n 27clean python=2.7 anaconda
source activate py27
conda install notebook ipykernel
ipython kernel install --user
ipython kernel install --user --name t35
(I screwed this one up)

How to open bash files for editing:

touch ~/.bash_profile; open ~/.bash_profile

source activate py27clean

You have to add the anaconda at the back otherwise the thing gets confused. 

# To activate this environment, use:
# > source activate 27clean
#
# To deactivate this environment, use:
# > source deactivate 27clean
#

# To activate this environment, use:
# > source activate 27
#
# To deactivate this environment, use:
# > source deactivate 27talib


Another thing to be very cautious of is what kernel you are using in ipython.

So far I only have these environments: 
27clean, 27talib etc that is worth using. 

inputs = {
    'open': open_1,
    'high': high,
    'low': low,
    'close': close,
    'volume': volume
}
# Wow this is interesting, you can specify the input arrays in the hope that
# the function will automatically pick them up.
# I like this idea, everything will process much quicker.



What this is awesome, there is actually a way to loop in parrallel, i.e. a simultaneous loop.

for f, b in zip(foo, bar):
    print(f, b)
    
You don't ever really have to change the variable name, you can just change the column name:

saved[lab] = i(inputs)

The approach to get_dummmies. 

Fuck that, i just created my own dummies:

    saved[b+'false_'+ cusi] = np.where(i(inputs) >99,1,0)
    saved[b+'true'+ cusi] = np.where(i(inputs) <-99,1,0)


But there is another way to do get dummies and this is with this procedure:

cols_to_transform = ['year', 'qtr']
frame = pd.get_dummies(avg, columns = cols_to_transform)
frame = pd.concat((frame, avg), axis=1)

This is how to fill numpy nan's with zeros:

here[np.isnan(here)] = 0

At the moment I have done min max scaling because it is noteably good for neural networks. If I find that the results are not to good, I might also look at producing standarisation techniques. 

You can't really do them together I have thought about that now. 

Can use command plus the arrow buttons to get to the end of along line. A lot like excel in fact. 

That is very interesting, instead of forcing a shit load of new variables, you can instead store all these "variables" away in a dictionary, this leads to much more efficent code. It kind of looks like a dataframe when you do this. 

NB there is a big distinction between append in lists: 

Append is essentially in a loop where each new item such as "burger", "pizza" etc gets appended one after the other in a long list.

However, when you have a pre-established list: list area = ["burger", "pizza"]
and blue = ["diamond", "liament"] then:
blue = blue + area to keep making a long list where one follows the other.

So the above should not use the append function. 

However, it does seem that you can add the function extend instead of the plus:

x.extend([4, 5])

This is how to do that fancy formatting printing:

print("%d. feature %d and %str (%f)" % (f + 1, indices[f], list(X)[indices[f]], importances[indices[f]]))


It's simply pointless to create variable variable names. Why?

They are unnecessary: You can store everything in lists, dictionarys and so on
They are hard to create: You have to use exec or globals()

How to select a certain cell in a pandas dataframe:

train.iloc[0]["photos"]

JSON's upload is tricky in that it is a little bit differnt to read:

# train = pd.read_json("train.json", "r")
You need the r, otherwise it does not give you all the level that you need. 

NB you can change the bash profile in just one line:
'

Steps:
Connect VPN
ssh dsno800@ml.cer.auckland.ac.nz
export PATH="/home/dsno800/anaconda3/bin:$PATH"
anaconda (TEST)

dsno800@ml.cer.auckland.ac.nz$$$$$$ jupyter notebook --no-browser --port=8890

For some reason, it only seems like you have to run the below code once
-----------------------------------------------------------------------------
derek:~ dereksnow$$$$$ ssh -N -f -L localhost:8888:localhost:8890 dsno800@ml.cer.auckland.ac.nz

You have to indeed follow all the steps
1 ,bluh. 

A cool way to do your password in one line:

echo 'D13sn33uman!' | sudo -S apt-get install unzip

There is an interesting service you can use to upload to a server.

Follow these steps:

How to move files around

ls into folder then
mv file new_folder 


! cd ~/Notebooks
# ! wget -x -c --load-cookies cookies.txt -P data -nH --cut-dirs=5 https://www.kaggle.com/dalpozz/creditcardfraud/downloads/creditcardfraud.zip
! cd ~/Notebooks/data
! ls

! wget -x -c --load-cookies cookies.txt -P data -nH --cut-dirs=5 https://www.kaggle.com/wendykan/lending-club-loan-data/downloads/lending-club-loan-data.zip

This is easy, it lists the header of the dataframe:

listed = list(df)

And this is how you can change the header with a list:
df.columns = listed

Use the one or the other depending on which one is fucking up:

from sklearn.cross_validation import train_test_split
from sklearn.model_selection import cross_validation

http://localhost:8888/tree/Lending/www.kaggle.com/wendykan/lending-club-loan-data/downloads




To install Python package from github, you need to clone that repository.

git clone https://github.com/jkbr/httpie.git
Then just run the setup.py file from that directory,

sudo python setup.py install

This is pretty interesting, you can get more head by incorporating the number in the head:
coeffdf.head(10)














































